{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-03-07 05:12:38]: Load data \n",
      "  Fold 0\n",
      "47959\n",
      "47959\n",
      "model_file: C:/Users/JasonLzF/sofia/model0_clf0.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data0_clf0.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data0_clf0.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred0_clf0.csv\n",
      "36605\n",
      "36605\n",
      "model_file: C:/Users/JasonLzF/sofia/model0_clf1.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data0_clf1.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data0_clf1.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred0_clf1.csv\n",
      "43098\n",
      "43098\n",
      "model_file: C:/Users/JasonLzF/sofia/model0_clf2.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data0_clf2.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data0_clf2.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred0_clf2.csv\n",
      "47350\n",
      "47350\n",
      "model_file: C:/Users/JasonLzF/sofia/model0_clf3.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data0_clf3.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data0_clf3.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred0_clf3.csv\n",
      "47310\n",
      "47310\n",
      "model_file: C:/Users/JasonLzF/sofia/model0_clf4.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data0_clf4.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data0_clf4.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred0_clf4.csv\n",
      "38194\n",
      "38194\n",
      "model_file: C:/Users/JasonLzF/sofia/model0_clf5.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data0_clf5.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data0_clf5.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred0_clf5.csv\n",
      "47231\n",
      "47231\n",
      "model_file: C:/Users/JasonLzF/sofia/model0_clf6.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data0_clf6.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data0_clf6.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred0_clf6.csv\n",
      "42731\n",
      "42731\n",
      "model_file: C:/Users/JasonLzF/sofia/model0_clf7.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data0_clf7.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data0_clf7.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred0_clf7.csv\n",
      "45538\n",
      "45538\n",
      "model_file: C:/Users/JasonLzF/sofia/model0_clf8.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data0_clf8.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data0_clf8.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred0_clf8.csv\n",
      "  Fold 1\n",
      "47959\n",
      "47959\n",
      "model_file: C:/Users/JasonLzF/sofia/model1_clf0.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data1_clf0.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data1_clf0.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred1_clf0.csv\n",
      "36604\n",
      "36604\n",
      "model_file: C:/Users/JasonLzF/sofia/model1_clf1.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data1_clf1.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data1_clf1.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred1_clf1.csv\n",
      "43099\n",
      "43099\n",
      "model_file: C:/Users/JasonLzF/sofia/model1_clf2.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data1_clf2.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data1_clf2.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred1_clf2.csv\n",
      "47349\n",
      "47349\n",
      "model_file: C:/Users/JasonLzF/sofia/model1_clf3.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data1_clf3.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data1_clf3.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred1_clf3.csv\n",
      "47311\n",
      "47311\n",
      "model_file: C:/Users/JasonLzF/sofia/model1_clf4.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data1_clf4.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data1_clf4.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred1_clf4.csv\n",
      "38194\n",
      "38194\n",
      "model_file: C:/Users/JasonLzF/sofia/model1_clf5.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data1_clf5.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data1_clf5.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred1_clf5.csv\n",
      "47231\n",
      "47231\n",
      "model_file: C:/Users/JasonLzF/sofia/model1_clf6.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data1_clf6.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data1_clf6.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred1_clf6.csv\n",
      "42731\n",
      "42731\n",
      "model_file: C:/Users/JasonLzF/sofia/model1_clf7.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data1_clf7.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data1_clf7.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred1_clf7.csv\n",
      "45538\n",
      "45538\n",
      "model_file: C:/Users/JasonLzF/sofia/model1_clf8.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data1_clf8.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data1_clf8.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred1_clf8.csv\n",
      "  Fold 2\n",
      "47959\n",
      "47959\n",
      "model_file: C:/Users/JasonLzF/sofia/model2_clf0.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data2_clf0.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data2_clf0.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred2_clf0.csv\n",
      "36604\n",
      "36604\n",
      "model_file: C:/Users/JasonLzF/sofia/model2_clf1.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data2_clf1.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data2_clf1.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred2_clf1.csv\n",
      "43099\n",
      "43099\n",
      "model_file: C:/Users/JasonLzF/sofia/model2_clf2.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data2_clf2.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data2_clf2.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred2_clf2.csv\n",
      "47349\n",
      "47349\n",
      "model_file: C:/Users/JasonLzF/sofia/model2_clf3.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data2_clf3.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data2_clf3.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred2_clf3.csv\n",
      "47311\n",
      "47311\n",
      "model_file: C:/Users/JasonLzF/sofia/model2_clf4.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data2_clf4.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data2_clf4.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred2_clf4.csv\n",
      "38194\n",
      "38194\n",
      "model_file: C:/Users/JasonLzF/sofia/model2_clf5.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data2_clf5.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data2_clf5.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred2_clf5.csv\n",
      "47231\n",
      "47231\n",
      "model_file: C:/Users/JasonLzF/sofia/model2_clf6.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data2_clf6.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data2_clf6.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred2_clf6.csv\n",
      "42731\n",
      "42731\n",
      "model_file: C:/Users/JasonLzF/sofia/model2_clf7.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data2_clf7.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data2_clf7.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred2_clf7.csv\n",
      "45538\n",
      "45538\n",
      "model_file: C:/Users/JasonLzF/sofia/model2_clf8.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data2_clf8.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data2_clf8.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred2_clf8.csv\n",
      "  Fold 3\n",
      "47960\n",
      "47960\n",
      "model_file: C:/Users/JasonLzF/sofia/model3_clf0.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data3_clf0.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data3_clf0.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred3_clf0.csv\n",
      "36605\n",
      "36605\n",
      "model_file: C:/Users/JasonLzF/sofia/model3_clf1.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data3_clf1.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data3_clf1.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred3_clf1.csv\n",
      "43100\n",
      "43100\n",
      "model_file: C:/Users/JasonLzF/sofia/model3_clf2.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data3_clf2.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data3_clf2.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred3_clf2.csv\n",
      "47350\n",
      "47350\n",
      "model_file: C:/Users/JasonLzF/sofia/model3_clf3.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data3_clf3.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data3_clf3.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred3_clf3.csv\n",
      "47312\n",
      "47312\n",
      "model_file: C:/Users/JasonLzF/sofia/model3_clf4.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data3_clf4.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data3_clf4.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred3_clf4.csv\n",
      "38195\n",
      "38195\n",
      "model_file: C:/Users/JasonLzF/sofia/model3_clf5.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data3_clf5.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data3_clf5.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred3_clf5.csv\n",
      "47232\n",
      "47232\n",
      "model_file: C:/Users/JasonLzF/sofia/model3_clf6.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data3_clf6.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data3_clf6.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred3_clf6.csv\n",
      "42731\n",
      "42731\n",
      "model_file: C:/Users/JasonLzF/sofia/model3_clf7.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data3_clf7.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data3_clf7.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred3_clf7.csv\n",
      "45539\n",
      "45539\n",
      "model_file: C:/Users/JasonLzF/sofia/model3_clf8.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data3_clf8.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data3_clf8.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred3_clf8.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 4\n",
      "47959\n",
      "47959\n",
      "model_file: C:/Users/JasonLzF/sofia/model4_clf0.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data4_clf0.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data4_clf0.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred4_clf0.csv\n",
      "36606\n",
      "36606\n",
      "model_file: C:/Users/JasonLzF/sofia/model4_clf1.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data4_clf1.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data4_clf1.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred4_clf1.csv\n",
      "43100\n",
      "43100\n",
      "model_file: C:/Users/JasonLzF/sofia/model4_clf2.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data4_clf2.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data4_clf2.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred4_clf2.csv\n",
      "47350\n",
      "47350\n",
      "model_file: C:/Users/JasonLzF/sofia/model4_clf3.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data4_clf3.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data4_clf3.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred4_clf3.csv\n",
      "47312\n",
      "47312\n",
      "model_file: C:/Users/JasonLzF/sofia/model4_clf4.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data4_clf4.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data4_clf4.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred4_clf4.csv\n",
      "38195\n",
      "38195\n",
      "model_file: C:/Users/JasonLzF/sofia/model4_clf5.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data4_clf5.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data4_clf5.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred4_clf5.csv\n",
      "47231\n",
      "47231\n",
      "model_file: C:/Users/JasonLzF/sofia/model4_clf6.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data4_clf6.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data4_clf6.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred4_clf6.csv\n",
      "42732\n",
      "42732\n",
      "model_file: C:/Users/JasonLzF/sofia/model4_clf7.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data4_clf7.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data4_clf7.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred4_clf7.csv\n",
      "45539\n",
      "45539\n",
      "model_file: C:/Users/JasonLzF/sofia/model4_clf8.model\n",
      "training_file: C:/Users/JasonLzF/sofia/train_data4_clf8.dat\n",
      "test_file: C:/Users/JasonLzF/sofia/test_data4_clf8.dat\n",
      "pred_file: C:/Users/JasonLzF/sofia/pred4_clf8.csv\n",
      "  Fold 0\n",
      "  Clf 0\n",
      "  Clf 1\n",
      "  Clf 2\n",
      "  Clf 3\n",
      "  Clf 4\n",
      "  Clf 5\n",
      "  Clf 6\n",
      "  Clf 7\n",
      "  Clf 8\n",
      "  logloss: 0.959012\n",
      "  Fold 1\n",
      "  Clf 0\n",
      "  Clf 1\n",
      "  Clf 2\n",
      "  Clf 3\n",
      "  Clf 4\n",
      "  Clf 5\n",
      "  Clf 6\n",
      "  Clf 7\n",
      "  Clf 8\n",
      "  logloss: 0.932488\n",
      "  Fold 2\n",
      "  Clf 0\n",
      "  Clf 1\n",
      "  Clf 2\n",
      "  Clf 3\n",
      "  Clf 4\n",
      "  Clf 5\n",
      "  Clf 6\n",
      "  Clf 7\n",
      "  Clf 8\n",
      "  logloss: 0.960469\n",
      "  Fold 3\n",
      "  Clf 0\n",
      "  Clf 1\n",
      "  Clf 2\n",
      "  Clf 3\n",
      "  Clf 4\n",
      "  Clf 5\n",
      "  Clf 6\n",
      "  Clf 7\n",
      "  Clf 8\n",
      "  logloss: 0.949004\n",
      "  Fold 4\n",
      "  Clf 0\n",
      "  Clf 1\n",
      "  Clf 2\n",
      "  Clf 3\n",
      "  Clf 4\n",
      "  Clf 5\n",
      "  Clf 6\n",
      "  Clf 7\n",
      "  Clf 8\n",
      "  logloss: 0.987236\n",
      "model average logloss: 0.957642\n",
      "[2020-03-07 05:19:37]: Run complete: 0:06:58 elapsed \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# from svmlight_loader import dump_svmlight_file\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "import subprocess\n",
    "from subprocess import call, check_output\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "# import pegasos\n",
    "\n",
    "\n",
    "def elapsed_time(start_time, end_time):\n",
    "    elapsed_sec = end_time - start_time\n",
    "    h = int(elapsed_sec / (60 * 60))\n",
    "    m = int((elapsed_sec % (60 * 60)) / 60)\n",
    "    s = int(elapsed_sec % 60)\n",
    "    return \"{}:{:>02}:{:>02}\".format(h, m, s)\n",
    "\n",
    "def evaluate(y, y_pred):\n",
    "    logloss = log_loss(y, y_pred)\n",
    "    return logloss\n",
    "\n",
    "def rSubset(arr, r): \n",
    "  \n",
    "    # return list of all subsets of length r \n",
    "    # to deal with duplicate subsets use  \n",
    "    # set(list(combinations(arr, r))) \n",
    "    return list(combinations(arr, r)) \n",
    "\n",
    "def load_data(train_data_path='data/train.csv', test_data_path = 'data/test.csv'):\n",
    "    train_df = pd.read_csv(train_data_path, sep=',', index_col=0, header=0)\n",
    "    test_df = pd.read_csv(test_data_path, sep=',', index_col=0, header=0)\n",
    "    \n",
    "    train_df['target'] = train_df['target'].str[-1].astype(int) - 1\n",
    "        \n",
    "    return train_df, test_df\n",
    "\n",
    "def export_CV_data(X, y, X_submission, n_classes, n_folds=5):\n",
    "    # change these filenames to reflect your system\n",
    "    file_prefix = \"C:/Users/JasonLzF/sofia/\"\n",
    "#     file_prefix = \"\"\n",
    "    \n",
    "    skf = list(StratifiedKFold(n_folds, random_state=0, shuffle=True).split(X, y))\n",
    "    \n",
    "    for i, (train_idx, test_idx) in enumerate(skf):\n",
    "        print (\"  Fold %d\" % i)\n",
    "        X_train = X[train_idx]\n",
    "        y_train = y[train_idx]\n",
    "        X_test = X[test_idx]\n",
    "        y_test = y[test_idx]\n",
    "        \n",
    "        for j in range(0, n_classes):\n",
    "            # note that for sofia-ml (and vowpal wabbit), labels need to be {-1,1}, not {0,1}, so we change them\n",
    "            print((y_train != j).sum(0))\n",
    "            tmp_y_train = np.copy(y_train)\n",
    "            tmp_y_train[y_train == j] = 1\n",
    "            tmp_y_train[y_train != j] = -1\n",
    "            print((tmp_y_train == -1).sum(0))\n",
    "            \n",
    "            # change filenames \n",
    "            model_file = file_prefix + \"model\" + str(i) + \"_clf\" + str(j) + \".model\"\n",
    "            training_file = file_prefix + \"train_data\" + str(i) + \"_clf\" + str(j) + \".dat\"\n",
    "            test_file = file_prefix + \"test_data\" + str(i) + \"_clf\" + str(j) + \".dat\"\n",
    "            pred_file = file_prefix + \"pred\" + str(i) + \"_clf\" + str(j) + \".csv\"\n",
    "            print(\"model_file: \" + model_file)\n",
    "            print(\"training_file: \" + training_file)\n",
    "            print(\"test_file: \" + test_file)\n",
    "            print(\"pred_file: \" + pred_file)\n",
    "            \n",
    "            # export data\n",
    "            dump_svmlight_file(X_train, tmp_y_train, training_file, zero_based=False)\n",
    "            dump_svmlight_file(X_test, np.zeros((X_test.shape[0],)), test_file, zero_based=False)\n",
    "            \n",
    "def export_data(X_submission):\n",
    "    # change these filenames to reflect your system\n",
    "    file_prefix = \"C:/Users/JasonLzF/sofia/\"\n",
    "#     file_prefix = \"\"\n",
    "    test_file = file_prefix + \"test_data.dat\"\n",
    "    \n",
    "    # export data\n",
    "    dump_svmlight_file(X_submission, np.zeros((X_submission.shape[0],)), test_file, zero_based=False)\n",
    "\n",
    "def model_CV_train(X, y, X_submission, loop_type, n_classes, n_folds=5):\n",
    "    summary = {}\n",
    "\n",
    "    file_prefix = \"\\\"C:/Users/JasonLzF/sofia\"\n",
    "    file_prefix_ = \"C:/Users/JasonLzF/sofia\"\n",
    "    test_file_ = file_prefix + \"/test_data.dat\\\"\"\n",
    "    skf = list(StratifiedKFold(n_folds, random_state=0, shuffle=True).split(X, y))\n",
    "    \n",
    "    stack_train = np.zeros((X.shape[0], n_classes))\n",
    "    stacklg_train = np.zeros((X.shape[0], n_classes))\n",
    "    stack_test = np.zeros((X_submission.shape[0], n_classes))\n",
    "    \n",
    "#     print(\"Model :\" model)\n",
    "\n",
    "    avg_logloss = 0\n",
    "    avglg_logloss = 0\n",
    "\n",
    "    stack_test_model = np.zeros((X_submission.shape[0], n_classes, len(skf)))\n",
    "    for i, (train_idx, test_idx) in enumerate(skf):\n",
    "        print (\"  Fold %d\" % i)\n",
    "        X_train = X[train_idx]\n",
    "        y_train = y[train_idx]\n",
    "        X_test = X[test_idx]\n",
    "        y_test = y[test_idx]\n",
    "        \n",
    "#         for i in range(0, 9):\n",
    "#             print((y_test == i).sum(0))\n",
    "#         print((y_test == 3).sum(0) / y_test.shape[0])\n",
    "        for j in range(0, n_classes):  \n",
    "            print (\"  Clf %d\" % j)\n",
    "            # change filenames \n",
    "            model_file = file_prefix + \"/model\" + str(i) + \"_clf\" + str(j) + \".model\\\"\"\n",
    "            training_file = file_prefix + \"/train_data\" + str(i) + \"_clf\" + str(j) + \".dat\\\"\"\n",
    "            test_file = file_prefix + \"/test_data\" + str(i) + \"_clf\" + str(j) + \".dat\\\"\"\n",
    "            pred_file = file_prefix + \"/pred\" + str(i) + \"_clf\" + str(j) + \".csv\\\"\"\n",
    "            pred_file_test = file_prefix + \"/pred_test\" + str(i) + \"_clf\" + str(j) + \".csv\\\"\"\n",
    "#             print(\"model_file: \" + model_file)\n",
    "#             print(\"training_file: \" + training_file)\n",
    "#             print(\"test_file: \" + test_file)\n",
    "#             print(\"pred_file: \" + pred_file)\n",
    "            \n",
    "            # train via subprocess call\n",
    "#             call(\"sofia-ml.exe --learner_type logreg-pegasos --loop_type balanced-stochastic --prediction_type logistic --iterations 100000 --training_file \"+training_file+\" --model_out \"+model_file, shell = True)\n",
    "            check_output(\"sofia-ml.exe --rank_step_probability 0.8 --lambda 0.001 --passive_aggressive_c 0.1 --passive_aggressive_lambda 0.001 --iterations 300000 --learner_type logreg-pegasos --loop_type \"+loop_type+\" --prediction_type logistic --training_file \"+training_file+\" --model_out \"+model_file, shell = True)\n",
    "#             call(\"sofia-ml.exe --learner_type logreg-pegasos --loop_type combined-roc --prediction_type logistic --training_file \"+training_file+\" --model_out \"+model_file, shell = True)\n",
    "            # create test data via subprocess call\n",
    "            check_output(\"sofia-ml.exe --model_in \"+model_file+\" --test_file \"+test_file+\" --results_file \"+pred_file, shell = True)\n",
    "#             call(\"sofia-ml.exe --model_in \"+model_file+\" --test_file \"+training_file+\" --results_file \"+pred_file, shell = True)\n",
    "            check_output(\"sofia-ml.exe --model_in \"+model_file+\" --test_file \"+test_file_+\" --results_file \"+pred_file_test, timeout = 100, shell = True) \n",
    "#             print('train&predict done')\n",
    "    \n",
    "            # read in test data\n",
    "#             to_numpy()\n",
    "            pred_file = file_prefix_ + \"/pred\" + str(i) + \"_clf\" + str(j) + \".csv\"\n",
    "            pred_file_test = file_prefix_ + \"/pred_test\" + str(i) + \"_clf\" + str(j) + \".csv\"\n",
    "            pred_prob  = pd.io.parsers.read_csv(pred_file, sep=\"\\t\", names=[\"pred\",\"true\"])['pred'] \n",
    "            pred_prob_test  = pd.io.parsers.read_csv(pred_file_test, sep=\"\\t\", names=[\"pred\",\"true\"])['pred']\n",
    "            \n",
    "            # do logistic transformation to get probabilities\n",
    "            pred_prob = 1./(1.+np.exp(-pred_prob))\n",
    "            pred_prob_test = 1./(1.+np.exp(-pred_prob_test))\n",
    "            \n",
    "#             stack_train[test_idx, j] = pred_prob[:, 1]\n",
    "            stack_train[test_idx, j] = pred_prob\n",
    "            stack_test_model[:, j, i] = pred_prob_test\n",
    "#             print('assign')\n",
    "\n",
    "        logloss = evaluate(y_test, stack_train[test_idx, :])\n",
    "        avg_logloss += logloss\n",
    "        print (\"  logloss: %f\" % logloss)\n",
    "    avg_logloss = avg_logloss / n_folds\n",
    "    print (\"model average logloss: %f\" % avg_logloss)\n",
    "    summary = avg_logloss\n",
    "    stack_test[:, :] = stack_test_model.mean(axis=2)\n",
    "\n",
    "    return stack_train, stack_test, summary\n",
    "\n",
    "def get_model_stack_test(n_classes=9, n_folds=5):\n",
    "    stack_test = np.zeros((X_submission.shape[0], n_classes))\n",
    "    stack_test_model = np.zeros((X_submission.shape[0], n_classes, n_folds))\n",
    "    file_prefix_ = \"C:/Users/JasonLzF/sofia\"\n",
    "    \n",
    "    for i in range(n_folds):\n",
    "        for j in range(n_classes):\n",
    "            pred_file_test = file_prefix_ + \"/pred_test\" + str(i) + \"_clf\" + str(j) + \".csv\"\n",
    "            pred_prob_test  = pd.io.parsers.read_csv(pred_file_test, sep=\"\\t\", names=[\"pred\",\"true\"])['pred']\n",
    "            \n",
    "            # do logistic transformation to get probabilities\n",
    "            pred_prob_test = 1./(1.+np.exp(-pred_prob_test))\n",
    "            \n",
    "            stack_test_model[:, j, i] = pred_prob_test\n",
    "    stack_test[:, :] = stack_test_model.mean(axis=2)\n",
    "    \n",
    "    return stack_test       \n",
    "\n",
    "def generate_sets():\n",
    "    # 3 level interactions\n",
    "    arr = [33, 47, 15, 38, 61, 67, 59, 66, 21, 17, 13, 10, 42]\n",
    "    sets = rSubset(arr, 3)\n",
    "    print('number of sets' + str(len(sets)))\n",
    "    random.seed(30)\n",
    "    sa = random.sample(range(0, len(sets)), 4)\n",
    "    sets1 = []\n",
    "    for i in sa:\n",
    "        print(i)\n",
    "        sets1.append(sets[i])\n",
    "        print(sets1)\n",
    "        \n",
    "    for set in sets1:\n",
    "        print(set)\n",
    "    \n",
    "    return sets1\n",
    "\n",
    "def interactions(sets, X, y, X_submission, Xcs, Xcs_submission, transform_):\n",
    "    summaries = []\n",
    "    Xo = np.copy(X)\n",
    "    Xo_submission = np.copy(X_submission)\n",
    "#     Xc = np.copy(X)\n",
    "#     Xc_submission = np.copy(X_submission)\n",
    "    \n",
    "#     Xcs = np.copy(Xo)\n",
    "#     Xcs_submission = np.copy(Xo_submission)\n",
    "#     print('tsne starts')\n",
    "#     Xcs, y, Xcs_submission = process_data(Xcs, y, Xcs_submission, transform = 'tsne')\n",
    "#     print('tsne finishes')\n",
    "    X, y, X_submission = process_data(X, y, X_submission, transform = transform_)\n",
    "    X = np.hstack((X, Xcs))\n",
    "    X_submission = np.hstack((X_submission, Xcs_submission))\n",
    "    for set in sets:\n",
    "#         print(set)\n",
    "        new_feature = np.log1p(Xo[:, set[0]] * Xo[:, set[1]] * Xo[:, set[2]])\n",
    "#         if transform_ == 'log':\n",
    "#             new_feature += 1\n",
    "#         print((new_feature != 0).sum(0))\n",
    "        X = np.hstack((X, new_feature.reshape(-1, 1)))\n",
    "        new_feature_ = np.log1p(Xo_submission[:, set[0]] * Xo_submission[:, set[1]] * Xo_submission[:, set[2]])\n",
    "#         if transform_ == 'log':\n",
    "#             new_feature_ += 1\n",
    "        X_submission = np.hstack((X_submission, new_feature_.reshape(-1, 1)))\n",
    "    \n",
    "    if transform_ != 'log':\n",
    "        print('not log')\n",
    "        X, y, X_submission = process_data(X, y, X_submission, transform = transform_)\n",
    "#     X, y, X_submission = process_data(X, y, X_submission, transform = 'log')\n",
    "#         export_CV_data(X, y, X_submission, 9)\n",
    "#         train_models_pred, test_models_pred, summary = model_CV_train(X, y, X_submission, 9)\n",
    "#     summaries = np.hstack((summaries, summary))\n",
    "    \n",
    "    return X, y, X_submission\n",
    "\n",
    "def process_data(X, y, X_submission, ylabel='target', transform=None):\n",
    "#     X = train_df.drop(ylabel, axis=1).to_numpy()\n",
    "#     y = train_df[ylabel].to_numpy()\n",
    "#     X_submission = test_df.to_numpy()\n",
    "    print(transform)\n",
    "    \n",
    "    if len(transform.split()) == 1:\n",
    "        transform = transform.split()[0]\n",
    "    else:\n",
    "        k = int(transform.split()[1])\n",
    "        transform = transform.split()[0] \n",
    "#     print(transform, k)\n",
    "    \n",
    "    if transform == 'standarization':\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "        X = scaler.transform(X)\n",
    "        X_submission = scaler.transform(X_submission)\n",
    "    elif transform == 'log':\n",
    "        X = np.log1p(X)\n",
    "        X_submission = np.log1p(X_submission)\n",
    "    elif transform == 'sqrt':\n",
    "        X = np.sqrt(X + 3.0 / 8)\n",
    "        X_submission = np.sqrt(X_submission + 3.0 / 8)\n",
    "    elif transform == 'pca':\n",
    "        pca = PCA(n_components=3).fit(X)\n",
    "        X = pca.transform(X)\n",
    "        X_submission = pca.transform(X_submission)\n",
    "    elif transform == 'tsne':\n",
    "#         tsne = TSNE(n_components=3).fit(X)\n",
    "#         X = tsne.transform(X)\n",
    "#         X_submission = tsne.transform(X_submission)\n",
    "        X = TSNE(n_components=3).fit_transform(X)\n",
    "        X_submission = TSNE(n_components=3).fit_transform(X_submission)\n",
    "    elif transform == 'kmeans':\n",
    "        kmeans = KMeans(n_clusters = k).fit(X)\n",
    "        X = kmeans.labels_\n",
    "        X_submission = kmeans.predict(X_submission)\n",
    "    elif transform == 'pca+':\n",
    "        pca = PCA(n_components=3).fit(X)\n",
    "        X = np.hstack((X, pca.transform(X)))\n",
    "        X_submission = np.hstack((X, pca.transform(X)))\n",
    "    elif transform == 'tsne+':\n",
    "        tsne = TSNE(n_components=3).fit(X)\n",
    "        X = np.hstack((X, tsne.transform(X)))\n",
    "        X_submission = np.hstack((X_submission, tsne.transform(X_submission)))   \n",
    "#     print(X.shape)\n",
    "    return X, y, X_submission\n",
    "\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "\n",
    "    logging.basicConfig(level=logging.DEBUG,\n",
    "                        format='[%(asctime)s]: %(message)s ',\n",
    "                        datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                        stream=sys.stdout,\n",
    "                        filemode=\"w\"\n",
    "                        )\n",
    "\n",
    "    # load data\n",
    "    logging.info('Load data')\n",
    "    train_df, test_df = load_data(train_data_path='train.csv', test_data_path='test.csv')\n",
    "    \n",
    "    # Process data\n",
    "    X = train_df.drop('target', axis=1).to_numpy()\n",
    "    y = train_df['target'].to_numpy()\n",
    "    X_submission = test_df.to_numpy()\n",
    "    \n",
    "    # Model 11\n",
    "    Xo = np.copy(X)\n",
    "    Xo_submission = np.copy(X_submission)\n",
    "    Xo, y, Xo_submission = process_data(Xo, y, Xo_submission, transform = 'standarization')\n",
    "    \n",
    "    export_CV_data(Xo, y, Xo_submission, 9)\n",
    "    export_data(Xo_submission)\n",
    "    train_models_pred, test_models_pred, summary = model_CV_train(X, y, X_submission, \"balanced-stochastic\", 9)\n",
    "#     train_models_pred, test_models_pred, summary = model_CV_train(X, y, X_submission, \"combined-roc\", 9)\n",
    "#     test_models_pred = get_model_stack_test\n",
    "    \n",
    "    # Export predictions\n",
    "    np.savetxt(\"model11_train.csv\", train_models_pred, delimiter=\",\")\n",
    "    np.savetxt(\"model11_test.csv\", test_models_pred, delimiter=\",\")\n",
    "    \n",
    "    # Model 12\n",
    "    Xo = np.copy(X)\n",
    "    Xo_submission = np.copy(X_submission)\n",
    "    Xcs = np.copy(X)\n",
    "    Xcs_submission = np.copy(X_submission)\n",
    "    print('tsne starts')\n",
    "    Xcs, y, Xcs_submission = process_data(Xcs, y, Xcs_submission, transform = 'tsne')\n",
    "    print('tsne finishes')\n",
    "    np.savetxt(\"tsne_raw_train.csv\", Xcs, delimiter=\",\")\n",
    "    np.savetxt(\"tsne_raw_test.csv\", Xcs_submission, delimiter=\",\")\n",
    "    Xo, y, Xo_submission = interactions(generate_sets(), Xo, y, Xo_submission, Xcs, Xcs_submission,'standarization')\n",
    "    \n",
    "    export_CV_data(Xo, y, Xo_submission, 9)\n",
    "    export_data(Xo_submission)\n",
    "    train_models_pred, test_models_pred, summary = model_CV_train(X, y, X_submission, \"balanced-stochastic\", 9)\n",
    "    test_models_pred = get_model_stack_test\n",
    "    \n",
    "    # Export predictions\n",
    "    np.savetxt(\"model12_train.csv\", train_models_pred, delimiter=\",\")\n",
    "    np.savetxt(\"model12_test.csv\", test_models_pred, delimiter=\",\")\n",
    "    \n",
    "    # Model 13\n",
    "    Xo = np.copy(X)\n",
    "    Xo_submission = np.copy(X_submission)\n",
    "    Xcs = pd.read_csv(\"tsne_raw_train.csv\", header=None).to_numpy()\n",
    "    Xcs_submission = pd.read_csv(\"tsne_raw_test.csv\", header=None).to_numpy()\n",
    "    \n",
    "#     print(Xcs.shape)\n",
    "#     print(Xcs_submission.shape)\n",
    "#     print(np.log1p(Xcs))\n",
    "    Xo, y, Xo_submission = interactions(generate_sets(), Xo, y, Xo_submission, Xcs, Xcs_submission, 'log')\n",
    "    \n",
    "    export_CV_data(Xo, y, Xo_submission, 9)\n",
    "    export_data(Xo_submission)\n",
    "    train_models_pred, test_models_pred, summary = model_CV_train(X, y, X_submission, \"combined-roc\", 9)\n",
    "# #     test_models_pred = get_model_stack_test\n",
    "    \n",
    "#     # Export predictions\n",
    "    np.savetxt(\"model13_train.csv\", train_models_pred, delimiter=\",\")\n",
    "    np.savetxt(\"model13_test.csv\", test_models_pred, delimiter=\",\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    logging.info(\"Run complete: %s elapsed\" % elapsed_time(start_time, end_time))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jasonlzf\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in log\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
